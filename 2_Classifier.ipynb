{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:48:13.273521Z",
     "start_time": "2018-09-27T03:48:12.332382Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             fbeta_score, make_scorer, classification_report, confusion_matrix)\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:56:18.445628Z",
     "start_time": "2018-09-27T03:56:18.440839Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def create_train_test_sets(data, test_size=.2, downsample=False, downsample_fracs=None, binary_class=None):\n",
    "    if downsample_fracs is not None:\n",
    "        for c, f in downsample_fracs.items():\n",
    "            remove_mask = data[data['crashSeverity'] == c].sample(frac=f, random_state=seed).index\n",
    "            data = data.drop(remove_mask)\n",
    "            \n",
    "    y = data['crashSeverity']\n",
    "    X = data.drop('crashSeverity', axis=1)\n",
    "    \n",
    "    if binary_class is not None:\n",
    "        y = downsampled_ohe['crashSeverity'].apply(lambda _: 1 if _ == binary_class else 0)\n",
    "\n",
    "    if downsample:\n",
    "        rus = RandomUnderSampler(random_state=seed)\n",
    "        X, y = rus.fit_sample(X, y)\n",
    "\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:23.644835Z",
     "start_time": "2018-09-27T03:49:20.050576Z"
    }
   },
   "outputs": [],
   "source": [
    "crash_data_clean = pd.read_csv('Crash_Analysis_System_CAS_data_clean.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:23.869649Z",
     "start_time": "2018-09-27T03:49:23.646978Z"
    }
   },
   "outputs": [],
   "source": [
    "data = crash_data_clean.drop(['cornerRoadSideRoad', 'crashRPSH', 'directionRoleDescription'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:24.474479Z",
     "start_time": "2018-09-27T03:49:24.466496Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_type(dtype):\n",
    "    if dtype == 'int':\n",
    "        return np.int8\n",
    "    elif dtype == 'float':\n",
    "        return np.float\n",
    "    else:\n",
    "        return dtype\n",
    "\n",
    "# Read features descriptions\n",
    "features_catalog = pd.read_table('features_description.tsv')\n",
    "# Make a dict to use as dtypes for panda's dataframe\n",
    "features_dtypes = features_catalog.set_index('feature_name')['pandas_dtype'].apply(parse_type).to_dict()\n",
    "# Keep only the columns that remain in the clean version of the dataframe\n",
    "features_dtypes = {k: v for k, v in features_dtypes.items() if k in data.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:26.942030Z",
     "start_time": "2018-09-27T03:49:26.342722Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.astype(features_dtypes, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:27.593358Z",
     "start_time": "2018-09-27T03:49:27.393892Z"
    }
   },
   "outputs": [],
   "source": [
    "data['speedLimit'] = data['speedLimit'].apply(lambda x: 999 if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:28.206806Z",
     "start_time": "2018-09-27T03:49:27.595070Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = [f for f, t in features_dtypes.items() if t  == 'category']\n",
    "categorical_features.remove('crashSeverity')\n",
    "data_ohe = pd.get_dummies(data,columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about no need for feature scaling or transformation, nor normalizaton\n",
    "Why one hot encoding and not label encoding, why not ordinal labels and the need to have categorical features binarized\n",
    "\n",
    "Explore and choose the right metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">THIS SHOULD GO TO 1</span>\n",
    "\n",
    "The features `fatalCount`, `seriousInjuryCount`, `minorInjuryCount` are provided by the NZTA after the crash has been processed. Their values are not available at the time of the crah. At the same time, their values are almost completely correlated to our target variable, naturally.\n",
    "\n",
    "For example, a *fatal* crash will have a `fatalCount > 0`. But a *minor* crash will have `fatalCount` and `seriousInjuryCount` with a value of `0`. This can be seen for example, by training a Naive Bayes classifier while including the above features. Notice how both, the training and test performance metrics are high. This is due to data lakeage coming from this particular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:33.459391Z",
     "start_time": "2018-09-27T03:49:33.150388Z"
    }
   },
   "outputs": [],
   "source": [
    "# THIS SHOULD GO TO 1\n",
    "data_ohe.drop(['fatalCount', 'seriousInjuryCount', 'minorInjuryCount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build we train our models, we need to address the imbalance of classes present in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:49:41.766075Z",
     "start_time": "2018-09-27T03:49:41.753301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    444953\n",
       "M    140864\n",
       "S     34914\n",
       "F      5855\n",
       "Name: crashSeverity, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe['crashSeverity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we expect to get a usable model, we need to treat this situation somehow. To that end, and considering the vast amount crashes of class `N`, we will downsample this specific class. A downsample of 70% will remove a lot of the class'samples and yet it will still remain the most frequent one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:00.907897Z",
     "start_time": "2018-09-27T03:56:59.918098Z"
    }
   },
   "outputs": [],
   "source": [
    "down_fracs={'N': .9, 'M': .5}\n",
    "X_train, X_test, y_train, y_test = create_train_test_sets(data_ohe, test_size=.2, downsample_fracs=down_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:01.662619Z",
     "start_time": "2018-09-27T03:57:01.653890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    56485\n",
       "N    35455\n",
       "S    27961\n",
       "F     4655\n",
       "Name: crashSeverity, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, a word on the performance metrics we will be using to evaluate the different models below.\n",
    "\n",
    "Let us consider what metrics we should use. Towards that goal, we need to think about the applications of the predictions we want to make. Namely, given a fresh call informing an emergency agency of a car crash that just took place, we want to predict its severity so that the agency is able to dispatch the appropriate response. Here we are assuming that at this point in time we are provided with all the features present in the dataset. However, we understand that this sceneario is not always the case and so, a fully productionized impementation should incorporate a better handling of possible missing values (which we have cleaned and filled in for this project)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple metric that comes to mind naturally is *Accuracy*. That is, the ratio of the correctly predicted crashes among all samples. This includes both *True Positives* and *True Negatives*. Although, since we are in a multiclass case, we will perform a *One vs All classification* for each class –and then average the results. For clarification, the formula for accuracy is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy=\\sum_{i=1}^n x^i$$\n",
    "\n",
    "<span style=\"color: red\">Fix this and add other metrics</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red\">Explain whi we will use anf f1 score. Arugemnt for precision and recall both being important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:51:48.294284Z",
     "start_time": "2018-09-27T03:51:48.290533Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_results(true, pred, betta=1, digits=2, average=None):\n",
    "    print('Accuracy score: ', format(accuracy_score(true, pred)))\n",
    "    print('Precision score: ', format(precision_score(true, pred, average=average)))\n",
    "    print('Recall score: ', format(recall_score(true, pred, average=average)))\n",
    "    print('F1 score: ', format(f1_score(true, pred, average=average)))\n",
    "    print('F betta score with betta=%.2f: ' % betta, format(fbeta_score(true, pred, betta, average=average)))\n",
    "    print('\\n', classification_report(y_test, pred, digits=digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train a Naive Bayes classifier to use as a benchmark. As such, we won't be doing any hyperparameter tunning just yet. Its performance will be used as a baseline that we will work to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:22.524178Z",
     "start_time": "2018-09-27T03:57:21.998515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB_benchmark = MultinomialNB()\n",
    "clf_NB_benchmark.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T18:31:10.705971Z",
     "start_time": "2018-09-26T18:31:10.696105Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_NB_benchmark = joblib.load('clf_NB_benchmark.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T19:42:02.978843Z",
     "start_time": "2018-09-26T19:42:02.972511Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf_NB_benchmark, 'clf_NB_benchmark.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets throw in our test set and print some performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:27.356940Z",
     "start_time": "2018-09-27T03:57:26.946382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.40786769428387926\n",
      "Precision score:  0.45591294020598605\n",
      "Recall score:  0.40786769428387926\n",
      "F1 score:  0.41342028316644336\n",
      "F betta score with betta=1.00:  0.41342028316644336\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          F       0.10      0.50      0.17      1200\n",
      "          M       0.52      0.37      0.43     13947\n",
      "          N       0.48      0.62      0.54      9040\n",
      "          S       0.36      0.20      0.26      6953\n",
      "\n",
      "avg / total       0.46      0.41      0.41     31140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_NB = clf_NB_benchmark.predict(X_test)\n",
    "print_results(y_test, predictions_NB, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that all our reference metrics hover around the same values of 0.65.\n",
    "\n",
    "However, if we consider the same metrics at each class level, we see quite a different picture. First, we can clearly see that most of the weight in the global metric values comes from the `N` class. This is logical, considering most of the sample belong to this class. For each of the other three classes, we see values much lower.\n",
    "\n",
    "Lets remember that if a crash is of class `N`, then dispatching a response apprpriate for a fatal crash will not produce much inconvenience other than an economical one. However, if the crash is of class `F`, then dispatching a response team equiped to treat only a `N` crash is a serious problem.\n",
    "\n",
    "Looking for example at the metrics for class `F` we see a precision of only 3% and a recall of 49%. From the definition of precision and recall, this means that the `FP` for this class are much higher than the `TP` –thus producing a precision of 0.03— and that there are almost as much `TP` as there are `FN` –producing a recall value of 0.49.\n",
    "\n",
    "So, from the fact that there are almost as many `TP` as there are `FN` we conclude that we are missing a lot of relevant values –in fact, almost hanlf of them. On the other hand, the fact there are a lot more `FP` than `TP` tells us that the model is missclisifying a lot of crashes as being of class `F`.\n",
    "\n",
    "The case for classes `M` and `S` are similar.\n",
    "\n",
    "So, for any model that we train, we need to check that our performance metrics have an even behaviour across all classes. That is, ideally all the metrics should present low variability across classes, but at least the F1 score should present such behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will train a few model with different algorithms and search for the one that performs best. In order to choose the best performing algorithm, we will carefully analyze the same metrics from the previous section, plus AUC/ROC to compare between the models.\n",
    "\n",
    "Also, for each algorithm we will first train a model with all default values to get a baseline. Then we will do a grid search with relevant hyperparameter values to find the optimal combination.\n",
    "\n",
    "<span style=\"color:red\">explain how trees and ensembles are good wwhen we don't know the importance and relevance of features</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red\">explain pros and cons of RF for this problem</spam>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:41.939158Z",
     "start_time": "2018-09-27T03:57:39.374815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF_baseline = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "clf_RF_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-23T19:25:59.348620Z",
     "start_time": "2018-09-23T19:25:58.972346Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_RF_baseline = joblib.load('clf_RF_baseline.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T19:42:36.345176Z",
     "start_time": "2018-09-26T19:42:36.140683Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf_RF_baseline, 'clf_RF_baseline.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T03:57:44.759385Z",
     "start_time": "2018-09-27T03:57:44.073630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.4785806037251124\n",
      "Precision score:  0.4653496750627261\n",
      "Recall score:  0.4785806037251124\n",
      "F1 score:  0.4660370952966163\n",
      "F betta score with betta=1.00:  0.4660370952966163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          F    0.21544   0.10000   0.13660      1200\n",
      "          M    0.49838   0.61891   0.55215     13947\n",
      "          N    0.51894   0.47445   0.49569      9040\n",
      "          S    0.37255   0.26780   0.31161      6953\n",
      "\n",
      "avg / total    0.46535   0.47858   0.46604     31140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_RF = clf_RF_baseline.predict(X_test)\n",
    "print_results(y_test, predictions_RF, digits=5, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the benchmark classifier from section 3, we see that class `N` it greatly responsible for the final values of all metrics. But in this case, the behavior for the other classes is more disparate. Both precision and recall are way to low for classes `F`, `S` and `M`.\n",
    "\n",
    "So lets run a grid search. In this case we will try to find optimal values for the following hypermarameters:\n",
    "* Number of estimator\n",
    "* Max depth for trees\n",
    "* Minimum samples in leaf required to evaluate further splitting.\n",
    "\n",
    "For the number of estimators we will use values `[10, 20, 30, 40, 50]`. We should remember that each estimator is a decision tree built with a *bag* of samples ramdomly selected.\n",
    "\n",
    "Max depth is the parameter that will allow the trees to become more precise on their clasification, as each level further distills the impiruty of the samples than end up on each leaf. However, this parameters is also very much related to the overfitting of the trees. Although we are growing a forest in part to address this partial overfitting, we should aim for a balance. So, Considering the vast amount of features available, we will use values `[7, 9, 11, 13, 15, 17, 19]`.\n",
    "\n",
    "Finally, the minimum number on sample in a leaf required to perform another split is also a parameters related to overfitting and how pure are the samples in the final leaf nodes of the trees. Considering the size of the training set –about 43K samples– we will use the values `[50, 100, 500, 1000]` for the search.\n",
    "\n",
    "This combination of parameters will produce different model. We will use the default cross validation with a 3-fold to have good enough cross validation results without incurring in to much processing time; and F1 score to evaluate performance.\n",
    "\n",
    "Next, we run the search, time it and report on the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:04:29.450948Z",
     "start_time": "2018-09-27T04:04:15.158555Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=50 ..............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=50, score=0.4770026475155838, total=   6.1s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=50 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=50, score=0.4760372987231359, total=   6.7s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=50 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=50, score=0.47770911366026275, total=   6.0s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=100 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=100, score=0.47970031945357905, total=  11.0s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=100 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=100, score=0.47798013834254965, total=  11.3s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=100 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=100, score=0.47981050939543035, total=  11.1s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=200, score=0.4812403189371037, total=  22.2s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=200, score=0.47837414051293004, total=  21.6s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=200, score=0.48247015158345524, total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=300, score=0.4821030070645751, total=  32.8s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=300, score=0.47842045536937167, total=  32.6s\n",
      "[CV] max_depth=50, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=50, min_samples_split=2, n_estimators=300, score=0.483327108096616, total=  32.0s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=50, score=0.4932195692903205, total=   5.2s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=50, score=0.4891558064608526, total=   5.3s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=50, score=0.49194612087812284, total=   5.2s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=100, score=0.49598999501370983, total=   9.8s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=100, score=0.4902286438488652, total=   9.8s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=100, score=0.49439811371724113, total=   9.7s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=200, score=0.4934011772634385, total=  19.5s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=200, score=0.49137762787604994, total=  19.1s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=200, score=0.4946072009561492, total=  19.1s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=300, score=0.4943263911189551, total=  28.3s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=300, score=0.4905036154102127, total=  28.4s\n",
      "[CV] max_depth=50, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=10, n_estimators=300, score=0.49441303810138876, total=  28.7s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=50, score=0.49597918110356537, total=   4.9s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=50, score=0.4902669647641845, total=   4.9s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=50, score=0.49311304061353406, total=   4.9s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=100, score=0.49531025548715807, total=   9.2s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=100, score=0.49066185022890124, total=   9.3s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=100, score=0.4940018470042193, total=   9.2s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=200, score=0.4963885035160466, total=  18.0s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=200, score=0.49196373539648197, total=  18.2s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=200, score=0.49357987105453577, total=  18.4s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=300, score=0.49521097525297386, total=  27.7s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=300, score=0.49175100859837206, total=  26.9s\n",
      "[CV] max_depth=50, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=20, n_estimators=300, score=0.49418260911565753, total=  27.1s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=50, score=0.4938157211022186, total=   4.6s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=50, score=0.4893374185304864, total=   4.9s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=50, score=0.49265934059487765, total=   4.0s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=100, score=0.4930138838981255, total=   7.4s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=100, score=0.4887524410304038, total=   8.5s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=100, score=0.49195095969992425, total=   8.4s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=200, score=0.4944366604671483, total=  16.6s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=200, score=0.48804953804859963, total=  16.8s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=200, score=0.4931034419820443, total=  16.5s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=300, score=0.49538807820658565, total=  26.5s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=300, score=0.4874729443559036, total=  28.2s\n",
      "[CV] max_depth=50, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=50, min_samples_split=50, n_estimators=300, score=0.4931066439575156, total=  26.3s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=50 ..............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=50, score=0.4751490923392823, total=   6.3s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=50 ..............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=50, score=0.474601369957095, total=   7.0s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=50 ..............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=50, score=0.4756729637139336, total=   7.7s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=100 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=100, score=0.4779606839790718, total=  13.2s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=100 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=100, score=0.4770738218973275, total=  12.6s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=100 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=100, score=0.47878194372055527, total=  14.1s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=200, score=0.47806161078774684, total=  24.8s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=200, score=0.47854885841459066, total=  24.4s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=200 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=200, score=0.480787512294394, total=  22.0s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=300, score=0.47857554664526064, total=  36.3s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=300, score=0.47791322085120225, total=  39.7s\n",
      "[CV] max_depth=80, min_samples_split=2, n_estimators=300 .............\n",
      "[CV]  max_depth=80, min_samples_split=2, n_estimators=300, score=0.48189172065459596, total=  37.2s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=50, score=0.490427842957448, total=   5.6s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=50, score=0.48750758623931334, total=   5.5s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=50, score=0.4921654444929643, total=   5.8s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=100, score=0.49145545748405944, total=  11.1s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=100, score=0.4866065618038755, total=  11.4s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=100, score=0.4937885363290436, total=  12.3s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=200, score=0.4931872403671073, total=  22.9s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=200, score=0.4886734643391417, total=  25.1s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=200, score=0.4947093338016951, total=  20.1s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=300, score=0.4943588702906543, total=  35.2s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=300, score=0.48929072511411537, total=  32.2s\n",
      "[CV] max_depth=80, min_samples_split=10, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=10, n_estimators=300, score=0.4945909146888918, total=  31.5s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=50, score=0.49423707105444636, total=   5.4s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=50, score=0.49033003331164376, total=   5.4s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=50, score=0.4934516097779387, total=   5.9s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=100, score=0.4944382871518001, total=  10.1s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=100, score=0.4889971278919679, total=  10.3s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=100, score=0.4935080041465763, total=  10.7s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=200, score=0.4965363046778929, total=  17.1s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=200, score=0.49010880529265344, total=  20.2s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=200, score=0.49378822938480643, total=  20.2s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=300, score=0.495687340070612, total=  31.7s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=300, score=0.4904365106870779, total=  30.9s\n",
      "[CV] max_depth=80, min_samples_split=20, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=20, n_estimators=300, score=0.4940250649119538, total=  27.6s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=50, score=0.494276518350395, total=   4.6s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=50, score=0.4869533343870897, total=   4.6s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=50 .............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=50, score=0.49168393383899056, total=   4.5s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=100, score=0.4932041944568247, total=   8.8s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=100, score=0.4893942707090585, total=   8.9s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=100 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=100, score=0.49265397624130386, total=   8.5s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=200, score=0.4935626042849736, total=  16.7s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=200, score=0.48825962107224935, total=  16.8s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=200 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=200, score=0.49262380461995176, total=  16.8s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=300, score=0.4941407192728678, total=  24.9s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=300, score=0.48692331559204405, total=  25.4s\n",
      "[CV] max_depth=80, min_samples_split=50, n_estimators=300 ............\n",
      "[CV]  max_depth=80, min_samples_split=50, n_estimators=300, score=0.4931151619651156, total=  24.8s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=50, score=0.47454878497081127, total=   6.0s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=50, score=0.475507926540294, total=   6.1s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=50, score=0.4774551012836144, total=   6.0s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=100, score=0.47881591576889027, total=  11.2s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=100 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=100, score=0.47753591194849315, total=  11.4s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=100 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=100, score=0.480695888026194, total=  11.3s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=200, score=0.48031406764719814, total=  22.3s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=200, score=0.47957259367301835, total=  21.9s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=200, score=0.4800588095738166, total=  22.0s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=300, score=0.47875835048404325, total=  34.6s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=300, score=0.47817640583091886, total=  33.3s\n",
      "[CV] max_depth=100, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=100, min_samples_split=2, n_estimators=300, score=0.4810318546382062, total=  32.7s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=50, score=0.48999795429413623, total=   5.3s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=50, score=0.4870091587632388, total=   5.3s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=50, score=0.4910139449623124, total=   5.3s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=100, score=0.49142876297412946, total=   9.9s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=100, score=0.48729489391074843, total=   9.9s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=100, score=0.4931272640658375, total=   9.9s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=200, score=0.4940364579387779, total=  19.8s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=200, score=0.4889448993349616, total=  19.4s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=200, score=0.492954980390902, total=  19.4s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=300, score=0.4944376358455762, total=  28.7s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=300, score=0.4886758426895923, total=  30.2s\n",
      "[CV] max_depth=100, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=10, n_estimators=300, score=0.49280529452383004, total=  28.8s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=50, score=0.4940518100343089, total=   5.1s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=50, score=0.4906393198153662, total=   5.1s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=50, score=0.4927877892356135, total=   4.9s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=100, score=0.49467973258483455, total=   9.3s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=100, score=0.4892558417427359, total=   9.4s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=100, score=0.49469664509406147, total=   9.4s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=200, score=0.49618867128591804, total=  18.2s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=200, score=0.48990267647730623, total=  18.5s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=200, score=0.49375871483180345, total=  18.3s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=300, score=0.49487017089687996, total=  27.1s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=300, score=0.49008245816414403, total=  27.2s\n",
      "[CV] max_depth=100, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=20, n_estimators=300, score=0.4939883008055476, total=  27.4s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=50, score=0.49346900670694666, total=   4.9s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=50, score=0.4877748835760971, total=   5.1s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=50, score=0.4916705005435403, total=   5.0s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=100, score=0.49336302314319824, total=   8.7s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=100, score=0.490002016460731, total=   8.5s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=100, score=0.49276586172778286, total=   8.7s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=200, score=0.4937554468242843, total=  17.3s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=200, score=0.48838166093137025, total=  20.6s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=200, score=0.493214317628941, total=  20.3s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=300, score=0.49420719739962643, total=  26.0s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=300, score=0.486830867661043, total=  25.1s\n",
      "[CV] max_depth=100, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=100, min_samples_split=50, n_estimators=300, score=0.4933009989989502, total=  25.3s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=50, score=0.47457024341830445, total=   6.0s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=50, score=0.4754532798333981, total=   6.1s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=50 .............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=50, score=0.47747501430624006, total=   6.1s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=100 ............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=100, score=0.47881591576889027, total=  11.4s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=100 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=100, score=0.47753591194849315, total=  11.4s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=100 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=100, score=0.48071572714708644, total=  11.8s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=200, score=0.4803153679323024, total=  23.7s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=200, score=0.47957259367301835, total=  24.4s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=200 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=200, score=0.4800588095738166, total=  25.0s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=300, score=0.47875835048404325, total=  40.8s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=300, score=0.47817640583091886, total=  37.3s\n",
      "[CV] max_depth=200, min_samples_split=2, n_estimators=300 ............\n",
      "[CV]  max_depth=200, min_samples_split=2, n_estimators=300, score=0.4810318546382062, total=  35.3s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=50, score=0.48999795429413623, total=   5.5s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=50, score=0.4870091587632388, total=   5.4s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=50, score=0.4910139449623124, total=   5.5s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=100, score=0.49142876297412946, total=  10.6s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=100, score=0.48729489391074843, total=   8.7s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=100, score=0.4931272640658375, total=  10.3s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=200, score=0.4940364579387779, total=  20.6s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=200, score=0.4889448993349616, total=  20.4s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=200, score=0.492954980390902, total=  20.2s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=300, score=0.4944376358455762, total=  30.1s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=300, score=0.4886758426895923, total=  32.0s\n",
      "[CV] max_depth=200, min_samples_split=10, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=10, n_estimators=300, score=0.49280529452383004, total=  30.0s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=50, score=0.4940518100343089, total=   6.2s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=50, score=0.4906393198153662, total=   4.5s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=50, score=0.4927877892356135, total=   5.2s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=100, score=0.49467973258483455, total=  12.3s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=100, score=0.4892558417427359, total=  11.2s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=100, score=0.49469664509406147, total=  10.5s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=200, score=0.49618867128591804, total=  19.5s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=200, score=0.48990267647730623, total=  19.4s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=200, score=0.49375871483180345, total=  19.6s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=300, score=0.49487017089687996, total=  27.6s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=300, score=0.49008245816414403, total=  27.6s\n",
      "[CV] max_depth=200, min_samples_split=20, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=20, n_estimators=300, score=0.4939883008055476, total=  27.4s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=50, score=0.49346900670694666, total=   4.6s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=50, score=0.4877748835760971, total=   4.7s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=50 ............\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=50, score=0.4916705005435403, total=   4.6s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=100, score=0.49336302314319824, total=   9.2s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=100, score=0.490002016460731, total=  10.7s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=100 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=100, score=0.49276586172778286, total=   9.8s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=200, score=0.4937554468242843, total=  16.8s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=200, score=0.48838166093137025, total=  18.0s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=200 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=200, score=0.493214317628941, total=  17.5s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=300, score=0.49420719739962643, total=  25.0s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=300, score=0.486830867661043, total=  28.9s\n",
      "[CV] max_depth=200, min_samples_split=50, n_estimators=300 ...........\n",
      "[CV]  max_depth=200, min_samples_split=50, n_estimators=300, score=0.4933009989989502, total=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 192 out of 192 | elapsed: 59.8min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [50, 80, 100, 200],\n",
    "    'min_samples_split': [2, 10, 20, 50]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_RF_gridsearch = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "scorer = make_scorer(fbeta_score, beta=1, average='weighted')\n",
    "grid_obj_RF = GridSearchCV(clf_RF_gridsearch, parameters, scorer, verbose=4)\n",
    "grid_obj_RF = grid_obj_RF.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:07:07.369797Z",
     "start_time": "2018-09-27T05:07:07.364362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50, 'min_samples_split': 20, 'n_estimators': 200}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_obj_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:08:17.928910Z",
     "start_time": "2018-09-27T05:07:49.167311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = grid_obj_RF.best_estimator_\n",
    "best_rf.set_params(class_weight=None)\n",
    "best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:08:19.551126Z",
     "start_time": "2018-09-27T05:08:17.930693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5244380218368657\n",
      "Precision score:  0.5211566492292301\n",
      "Recall score:  0.5244380218368657\n",
      "F1 score:  0.4955682574381463\n",
      "F betta score with betta=1.00:  0.4955682574381463\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          F    0.44444   0.03667   0.06774      1200\n",
      "          M    0.50828   0.73944   0.60245     13947\n",
      "          N    0.59873   0.49204   0.54017      9040\n",
      "          S    0.45936   0.21947   0.29703      6953\n",
      "\n",
      "avg / total    0.52116   0.52444   0.49557     31140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_best_RF = best_rf.predict(X_test)\n",
    "print_results(y_test, predictions_best_RF, digits=5, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
