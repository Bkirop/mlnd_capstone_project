{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:49.185714Z",
     "start_time": "2018-09-18T01:18:47.450230Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:55.254280Z",
     "start_time": "2018-09-18T01:18:49.187978Z"
    }
   },
   "outputs": [],
   "source": [
    "crash_data_clean = pd.read_csv('Crash_Analysis_System_CAS_data_clean.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:55.267636Z",
     "start_time": "2018-09-18T01:18:55.255827Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_type(dtype):\n",
    "    if dtype == 'int':\n",
    "        return np.int8\n",
    "    elif dtype == 'float':\n",
    "        return np.float\n",
    "    else:\n",
    "        return dtype\n",
    "\n",
    "# Read features descriptions\n",
    "features_catalog = pd.read_table('features_description.tsv')\n",
    "# Make a dict to use as dtypes for panda's dataframe\n",
    "features_dtypes = features_catalog.set_index('feature_name')['pandas_dtype'].apply(parse_type).to_dict()\n",
    "# Keep only the columns that remain in the clean version of the dataframe\n",
    "features_dtypes = {k: v for k, v in features_dtypes.items() if k in crash_data_clean.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:56.025046Z",
     "start_time": "2018-09-18T01:18:55.270547Z"
    }
   },
   "outputs": [],
   "source": [
    "crash_data_clean = crash_data_clean.astype(features_dtypes, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:57.055598Z",
     "start_time": "2018-09-18T01:18:56.026738Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = list(features_catalog[features_catalog['feature_type'] == 'categorical']['feature_name'])\n",
    "categorical_features.remove('crashSeverity')\n",
    "crash_data_ohe = pd.get_dummies(crash_data_clean,columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:57.578426Z",
     "start_time": "2018-09-18T01:18:57.057667Z"
    }
   },
   "outputs": [],
   "source": [
    "y = crash_data_ohe['crashSeverity']\n",
    "X = crash_data_ohe.drop('crashSeverity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T01:18:58.391887Z",
     "start_time": "2018-09-18T01:18:57.582009Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">USE K-FOLD</span>\n",
    "\n",
    "also try:\n",
    "\n",
    "* Naive Bayes\n",
    "* sklearn.ensemble.GradientBoostingClassifier\n",
    "* XGBoost\n",
    "* LGBM\n",
    "* Bagging\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T02:19:51.263700Z",
     "start_time": "2018-09-18T02:19:44.716388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7654782516177082\n",
      "Precision score:  0.8131540565954025\n",
      "Recall score:  0.7654782516177082\n",
      "F1 score:  0.6917704120349837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def print_results(pred, true):\n",
    "    print('Accuracy score: ', format(accuracy_score(pred, true)))\n",
    "    print('Precision score: ', format(precision_score(pred, true, average='weighted')))\n",
    "    print('Recall score: ', format(recall_score(pred, true, average='weighted')))\n",
    "    print('F1 score: ', format(f1_score(pred, true, average='weighted')))\n",
    "\n",
    "clf_multi = MultinomialNB()\n",
    "\n",
    "clf_multi.fit(X_train, y_train)\n",
    "predictions = clf_gaussian.predict(X_test)\n",
    "print_results(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T02:07:13.723383Z",
     "start_time": "2018-09-18T02:07:13.718403Z"
    }
   },
   "source": [
    "One of the major advantages that Naive Bayes has over other classification algorithms is its ability to handle an extremely large number of features. In our case, each word is treated as a feature and there are thousands of different words. Also, it performs well even with the presence of irrelevant features and is relatively unaffected by them. The other major advantage it has is its relative simplicity. Naive Bayes' works well right out of the box and tuning it's parameters is rarely ever necessary, except usually in cases where the distribution of the data is known. \n",
    "It rarely ever overfits the data. Another important advantage is that its model training and prediction times are very fast for the amount of data it can handle. All in all, Naive Bayes' really is a gem of an algorithm!\n",
    "\n",
    "Congratulations! You have successfully designed a model that can efficiently predict if an SMS message is spam or not!\n",
    "\n",
    "Thank you for learning with us!\n",
    "\n",
    "HOW TO DO ROC/AUC?\n",
    "HOW TO IMPROVE THESE METRICS?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
